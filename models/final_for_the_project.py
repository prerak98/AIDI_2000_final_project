# -*- coding: utf-8 -*-
"""final_for the project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FZSI-V8X6QqqNG4bA36X2OZL-K1gJ_hX
"""

import json
import numpy as np
import pandas as pd
import librosa

# Load the preprocessed data
with open('../output/preprocessed_data.json', 'r') as f:
    data = [json.loads(line) for line in f]

df = pd.DataFrame(data)

# Convert lists back to numpy arrays
df['mfcc'] = df['mfcc'].apply(lambda x: np.array(x))
df['chroma'] = df['chroma'].apply(lambda x: np.array(x))
df['spectral_contrast'] = df['spectral_contrast'].apply(lambda x: np.array(x))

# Prepare the feature matrix (X) and target vector (y)
X = np.hstack([
    np.vstack(df['mfcc'].values),
    np.vstack(df['chroma'].values),
    np.vstack(df['spectral_contrast'].values)
])
y = df['emotion']

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from keras import layers, models

# Encode the labels (y)
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# Feature normalization
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Reshape the data for the CNN
X_scaled = X_scaled.reshape(-1, X_scaled.shape[1], 1)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)

# Build the CNN model
model = models.Sequential([
    layers.Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], 1)),
    layers.MaxPooling1D(2),
    layers.Conv1D(64, 3, activation='relu'),
    layers.MaxPooling1D(2),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(len(np.unique(y_train)), activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the CNN model
model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))

# Save the model
model.save('cnn_model.keras')

# Evaluate the CNN model
cnn_accuracy = model.evaluate(X_test, y_test)[1]
print(f"CNN Model Accuracy: {cnn_accuracy:.4f}")

import tensorflow as tf
from pydub import AudioSegment
import librosa

# Convert m4a to wav
def convert_m4a_to_wav(m4a_file, wav_file):
    audio = AudioSegment.from_file(m4a_file, format="m4a")
    audio.export(wav_file, format="wav")

# Convert your .m4a file to .wav
m4a_path = '/Durham College.m4a'  # Update this path if necessary
wav_path = 'Durham_College.wav'
convert_m4a_to_wav(m4a_path, wav_path)

# Load the audio file
y, sr = librosa.load(wav_path, sr=None)

# Extract features
mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
chroma = librosa.feature.chroma_stft(y=y, sr=sr)
spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)

# Stack features together (adjust as necessary based on your model)
features = np.hstack([mfcc.mean(axis=1), chroma.mean(axis=1), spectral_contrast.mean(axis=1)])

# Load the saved StandardScaler if available, otherwise use the features as-is
try:
    with open('scaler.pkl', 'rb') as f:
        scaler = pickle.load(f)
    features_scaled = scaler.transform(features.reshape(1, -1))
except FileNotFoundError:
    features_scaled = features.reshape(1, -1)  # Proceed without scaling

# Reshape for the CNN input
features_scaled = features_scaled.reshape(-1, features_scaled.shape[1], 1)

# Load the trained model
model = tf.keras.models.load_model('cnn_model.keras')

# Make prediction
prediction = model.predict(features_scaled)
predicted_emotion_index = np.argmax(prediction)

# Define the mapping (adjust this based on your specific case)
emotion_mapping = {
    0: "angry",
    1: "happy",
    2: "sad",
    3: "neutral",
    4: "fearful",
    5: "disgust",
    6: "surprised"
}

# Get the emotion label
predicted_emotion_label = emotion_mapping.get(predicted_emotion_index, "Unknown Emotion")
print(f"Predicted Emotion: {predicted_emotion_label}")